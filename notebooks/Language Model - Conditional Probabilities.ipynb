{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "from nltk import bigrams, trigrams\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sentences of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\n",
    "for doc in os.listdir(\"../data/definitions/prediction/\"):\n",
    "    if doc.endswith(\".txt\"):\n",
    "        text = open(\"../data/definitions/prediction/\"+doc, \"r\").read()\n",
    "        corpus += text\n",
    "\n",
    "sents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dict that holds frequencies of words following a bigram\n",
    "<ol>\n",
    "    <li>Iterate words of each sentence and remove punctuation</li>\n",
    "    <li>Get trigrams of sentence with padding left and right</li>\n",
    "    <li>Save first two words as key and last word as follower and increase count</li>\n",
    "</ol>\n",
    "<br/>\n",
    "<b>Parameters 'pad_left' and 'pad_right' in Trigrams are used to get the following:</b> <br/>\n",
    "<b>Example sentence:</b> $$\"Clustering\\:is\\:nice\"$$<br/>\n",
    "<b>Without params:</b> $$[(\"Clustering\", \"is\", \"nice\")]$$\n",
    "<b>With padding:</b> $$[(None,\\:None,\\:\"Clustering\"), (None,\\:\"Clustering\", \"is\"), ... , (\"is\", \"nice\",\\:None), (\"nice\",\\:None,\\:None)]$$\n",
    "<br/>\n",
    "--> This allows to determine the frequency of words at the beginning of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:00<00:00, 1929.34it/s]\n"
     ]
    }
   ],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sent in tqdm(sents):\n",
    "    words = word_tokenize(sent)\n",
    "    words = [w.lower() for w in words if re.match(\"[a-z]+\", w.lower()) is not None]\n",
    "    tgs = trigrams(words, pad_left=True, pad_right=True)\n",
    "    for w1, w2, w3 in tgs:\n",
    "        model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "# Amount of sentences starting with \"The\"\n",
    "print(model[None, None][\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the conditional Probabilities\n",
    "For each stored trigram the probability $P(w3|w1, w2)$ is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [00:00<00:00, 279392.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for w1_w2 in tqdm(model):\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16201117318435754\n"
     ]
    }
   ],
   "source": [
    "# Probability of a sentence starting with \"the\"\n",
    "print(model[(None, None)][\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new sentences\n",
    "Using a random number to ensure that not only the words with highest probability gets assigned as next word, because this will result in almost identical sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of text=4.6319015258922035e-127\n",
      "when there is no precise definition of an outlier outliers are observations which do not imply order\n",
      "\n",
      "\n",
      "Probability of text=1.0573121510623575e-142\n",
      "like all forms of regression analysis it is a category of regression analysis can be applied to the discrete response variables used in finance investing and other is\n",
      "\n",
      "\n",
      "Probability of text=1.1303796588322627e-191\n",
      "predicting values outside of the explanatory variables are predicted rather than on the joint probability distribution of the response\n",
      "\n",
      "\n",
      "Probability of text=1.2045457987219775e-71\n",
      "using the least squares least absolute deviations minimizing the sum of absolute values of residuals and the y-axis would represent the child iq score would be.regression analysis is\n",
      "\n",
      "\n",
      "Probability of text=3.0320700648629e-126\n",
      "under this hypothesis the accuracy of classification rules can be accurately expressed by the other independent variables are collected without an accompanying response value the fitted line is\n",
      "\n",
      "\n",
      "Probability of text=2.619852142002662e-157\n",
      "statistical relationship is not accurate in determining relationship between the response at all or to identify which subsets of explanatory variables linear regression where a change in x\n",
      "\n",
      "\n",
      "Probability of text=2.406785252046932e-58\n",
      "in simple linear regression has many practical uses\n",
      "\n",
      "\n",
      "Probability of text=9.023019608035752e-92\n",
      "in linear regression where a model is created for the relationship between target and one dependent variable values as a dot on a graph so that you can\n",
      "\n",
      "\n",
      "Probability of text=1.2106894600589043e-50\n",
      "in this case given how long a child is breastfed it enables you to predict continuous valued output take this example\n",
      "\n",
      "\n",
      "Probability of text=8.645461963694303e-83\n",
      "more specifically referred to as y\n",
      "\n",
      "\n",
      "Probability of text=7.149312368806051e-72\n",
      "the performance of regression such as commodity prices and the goal of classification problem is binary classification the target attribute has only two possible values for example if\n",
      "\n",
      "\n",
      "Probability of text=1.4288762279122054e-80\n",
      "before attempting to fit models that are not synonymous.in statistics simple linear regression because it does not prove causation\n",
      "\n",
      "\n",
      "Probability of text=2.4521083708206582e-83\n",
      "robust regression methods that can be a helpful tool in determining relationship between one or more predictors.in regression problems we trying to predict continuous valued output take this\n",
      "\n",
      "\n",
      "Probability of text=3.9353347172996035e-44\n",
      "the case of one explanatory variable\n",
      "\n",
      "\n",
      "Probability of text=1.4992578107208084e-54\n",
      "using the regression equation to predict categorical class labels and prediction models predict continuous valued output take this example\n",
      "\n",
      "\n",
      "Probability of text=7.095713169323602e-55\n",
      "the data must supply the model structure as well as the line of best fit and it tells you by how much you ll weigh in ten years\n",
      "\n",
      "\n",
      "Probability of text=2.8420635831754712e-27\n",
      "people use regression on an intuitive level every day\n",
      "\n",
      "\n",
      "Probability of text=1.3293936379146248e-111\n",
      "less commonly the conditional probability distribution of all of the relationship between variables\n",
      "\n",
      "\n",
      "Probability of text=4.45279234872657e-133\n",
      "relationship between variables\n",
      "\n",
      "\n",
      "Probability of text=3.948828114832449e-71\n",
      "these assumptions are moderately violated although they may also be fitted in other ways such as commodity prices and the explanatory variables may contain redundant information about the\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(20):\n",
    "    text = [None, None]\n",
    "    prob = 1.0\n",
    "    sentence_finished = False\n",
    "\n",
    "    while not sentence_finished:\n",
    "        # r = random.random()\n",
    "        r = random.uniform(0.5, 1)\n",
    "        # print(\"Random: {}\".format(r))\n",
    "        accumulator = .0\n",
    "        # print(\"Possible words: {}\".format(len(model[tuple(text[-2:])].keys())))\n",
    "        for word in model[tuple(text[-2:])].keys():\n",
    "            accumulator += model[tuple(text[-2:])][word]\n",
    "            # print(\"Accumulator: {}\".format(accumulator))\n",
    "            # print(\"=> {}\".format( accumulator >= r))\n",
    "            prob *= model[tuple(text[-2:])][word]  \n",
    "            if accumulator >= r:\n",
    "                text.append(word)\n",
    "                break\n",
    "\n",
    "        if text[-2:] == [None, None] or len(text) == 30:\n",
    "            sentence_finished = True\n",
    "    if len(text) > 6:\n",
    "        if not os.path.exists(\"../data/sentence_generation_outputs\"):\n",
    "            os.mkdir(\"../data/sentence_generation_outputs/\")\n",
    "        file = open(\"../data/sentence_generation_outputs/sentence_{}.txt\".format(i+1), \"w\")\n",
    "        file.write(' '.join([t for t in text if t]))\n",
    "        \n",
    "        print(\"Probability of text={}\".format(prob))\n",
    "        print(' '.join([t for t in text if t]))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
