{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "from nltk import bigrams, trigrams\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sentences of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\n",
    "for doc in os.listdir(\"../data/definitions/clustering/\"):\n",
    "    if doc.endswith(\".txt\"):\n",
    "        text = open(\"../data/definitions/clustering/\"+doc, \"r\").read()\n",
    "        corpus += text\n",
    "\n",
    "sents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dict that holds frequencies of words following a bigram\n",
    "<ol>\n",
    "    <li>Iterate words of each sentence and remove punctuation</li>\n",
    "    <li>Get trigrams of sentence with padding left and right</li>\n",
    "    <li>Save first two words as key and last word as follower and increase count</li>\n",
    "</ol>\n",
    "<br/>\n",
    "<b>Parameters 'pad_left' and 'pad_right' in Trigrams are used to get the following:</b> <br/>\n",
    "<b>Example sentence:</b> $$\"Clustering\\:is\\:nice\"$$<br/>\n",
    "<b>Without params:</b> $$[(\"Clustering\", \"is\", \"nice\")]$$\n",
    "<b>With padding:</b> $$[(None,\\:None,\\:\"Clustering\"), (None,\\:\"Clustering\", \"is\"), ... , (\"is\", \"nice\",\\:None), (\"nice\",\\:None,\\:None)]$$\n",
    "<br/>\n",
    "--> This allows to determine the frequency of words at the beginning of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:00<00:00, 1891.15it/s]\n"
     ]
    }
   ],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sent in tqdm(sents):\n",
    "    words = word_tokenize(sent)\n",
    "    words = [w.lower() for w in words if re.match(\"[a-z]+\", w.lower()) is not None]\n",
    "    tgs = trigrams(words, pad_left=True, pad_right=True)\n",
    "    for w1, w2, w3 in tgs:\n",
    "        model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Amount of sentences starting with \"The\"\n",
    "print(model[None, None][\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the conditional Probabilities\n",
    "For each stored trigram the probability $P(w3|w1, w2)$ is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [00:00<00:00, 338005.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for w1_w2 in tqdm(model):\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14685314685314685\n"
     ]
    }
   ],
   "source": [
    "# Probability of a sentence starting with \"the\"\n",
    "print(model[(None, None)][\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new sentences\n",
    "Using a random number to ensure that not only the words with highest probability gets assigned as next word, because this will result in almost identical sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of text=2.896853168312344e-119\n",
      "clearly a cluster is left\n",
      "\n",
      "\n",
      "Probability of text=2.2102919891233269e-41\n",
      "\n",
      "\n",
      "\n",
      "Probability of text=4.1005498041968884e-158\n",
      "are sub-divided into groups in such a way that the items in a clear and meaningful way.clustering is a statistical method for finding relatively homogeneous clusters of data\n",
      "\n",
      "\n",
      "Probability of text=6.437285312285331e-109\n",
      "cluster analysis see gordon analysis or clustering is defined as a separate cluster i.e. there are as dissimilar as possible.cluster analysis is the organization of a sample of n subjects the observed values of several variables for each individual\n",
      "\n",
      "\n",
      "Probability of text=5.032138052900376e-54\n",
      "generally clustering is a statistical method for identifying homogenous groups of cases\n",
      "\n",
      "\n",
      "Probability of text=3.572744514274834e-88\n",
      "for instance in the former.statistical classification technique in which a set of genes that is coexpressed implies that the sample units come from a number of clusters we want the data without explaining why they exist.cluster analysis technique as a method of discovery by solving classification issues.cluster analysis is most appropriate of course depends on the observed values of several variables for each individual\n",
      "\n",
      "\n",
      "Probability of text=6.297874831296424e-22\n",
      "more specifically it tries to find patterns in the identification of an appropropriate form of therapy\n",
      "\n",
      "\n",
      "Probability of text=4.836921992097278e-84\n",
      "cluster analysis maximizes the similarity of cases if the grouping is not previously known\n",
      "\n",
      "\n",
      "Probability of text=4.109467111029835e-117\n",
      "cluster analysis are hierarchical methods and k-means relocation analysis based on dissimilarities or distances between objects in different groups such that the distance between these two subjects one from each other.cluster analysis is the formal study of algorithms and methods that spss offers can handle binary nominal ordinal and scale interval or ratio data.cluster analysis is a statistical tool used to label casewise output\n",
      "\n",
      "\n",
      "Probability of text=5.438863098760709e-151\n",
      "there are as similar as possible and documents in other words cluster analysis is to organize observed data for subject j by xj1 xj2 xjp while the euclidean distance between these two subjects is given by the nature of the data without explaining why they exist.cluster analysis technique as a vector of measurements or a point in the same group their degree of similarity or dissimilarity between groups that are available for classifying objects on the observed values of several variables for each individual\n",
      "\n",
      "\n",
      "Probability of text=7.304099339995701e-115\n",
      "unlike some other statistical techniques the structures that are thought to underlie the particular clustering phenomenon\n",
      "\n",
      "\n",
      "Probability of text=3.0642717849077213e-128\n",
      "both the similarity between two clusters is given bycluster analysis is similar in concept to discriminant analysis\n",
      "\n",
      "\n",
      "Probability of text=3.3565381956255713e-134\n",
      "often the researcher concentrates on one cluster solution with a certain number of clusters groups exist in the dataset and a common technique for discovering whether the individuals of a set of tools and algorithms that is they are like members of other clusters\n",
      "\n",
      "\n",
      "Probability of text=3.4925180208264255e-92\n",
      "perhaps the most straightforward and generally accepted way of computing distances between objects\n",
      "\n",
      "\n",
      "Probability of text=2.2102919891233269e-41\n",
      "\n",
      "\n",
      "\n",
      "Probability of text=7.786153960702586e-79\n",
      "it encompasses a number of distinct populations or sub-populations\n",
      "\n",
      "\n",
      "Probability of text=3.6960640189534556e-138\n",
      "different specific methods of hierarchical agglomerative cluster analysis simply discovers structures in order to gain further insight from them.cluster analysis is to find patterns in the variables studied called the cluster centroid\n",
      "\n",
      "\n",
      "Probability of text=4.2401393997989816e-94\n",
      "often the researcher concentrates on one cluster giving in all n-2 clusters\n",
      "\n",
      "\n",
      "Probability of text=3.0770593896591963e-128\n",
      "when we cluster the observations of a sample of observations is known upfront in the same group they have a maximal degree of association is minimal\n",
      "\n",
      "\n",
      "Probability of text=7.226881912983384e-98\n",
      "optionally you can select one of two methods for cluster analysis is an exploratory analysis that tries to identify distinct groups of potential customers so that for example advertising can be used to classify objects into groups clusters so that for example advertising can be used to label casewise output\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(20):\n",
    "    text = [None, None]\n",
    "    prob = 1.0\n",
    "    sentence_finished = False\n",
    "\n",
    "    while not sentence_finished:\n",
    "        # r = random.random()\n",
    "        r = random.uniform(0.3, 1)\n",
    "        # print(\"Random: {}\".format(r))\n",
    "        accumulator = .0\n",
    "        # print(\"Possible words: {}\".format(len(model[tuple(text[-2:])].keys())))\n",
    "        for word in model[tuple(text[-2:])].keys():\n",
    "            accumulator += model[tuple(text[-2:])][word]\n",
    "            # print(\"Accumulator: {}\".format(accumulator))\n",
    "            # print(\"=> {}\".format( accumulator >= r))\n",
    "            prob *= model[tuple(text[-2:])][word]  \n",
    "            if accumulator >= r:\n",
    "                text.append(word)\n",
    "                break\n",
    "\n",
    "        if text[-2:] == [None, None]:\n",
    "            sentence_finished = True\n",
    "    if len(text) > 6:\n",
    "        if not os.path.exists(\"../data/sentence_generation_outputs\"):\n",
    "            os.mkdir(\"../data/sentence_generation_outputs/\")\n",
    "        file = open(\"../data/sentence_generation_outputs/sentence_{}.txt\".format(i+1), \"w\")\n",
    "        file.write(' '.join([t for t in text if t]))\n",
    "        \n",
    "    print(\"Probability of text={}\".format(prob))\n",
    "    print(' '.join([t for t in text if t]))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
