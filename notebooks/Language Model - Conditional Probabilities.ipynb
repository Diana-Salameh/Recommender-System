{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "from nltk import bigrams, trigrams\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sentences of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\n",
    "for doc in os.listdir(\"../data/definitions/clustering/\"):\n",
    "    if doc.endswith(\".txt\"):\n",
    "        text = open(\"../data/definitions/clustering/\"+doc, \"r\").read()\n",
    "        corpus += text\n",
    "\n",
    "sents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dict that holds frequencies of words following a bigram\n",
    "<ol>\n",
    "    <li>Iterate words of each sentence and remove punctuation</li>\n",
    "    <li>Get trigrams of sentence with padding left and right</li>\n",
    "    <li>Save first two words as key and last word as follower and increase count</li>\n",
    "</ol>\n",
    "<br/>\n",
    "<b>Parameters 'pad_left' and 'pad_right' in Trigrams are used to get the following:</b> <br/>\n",
    "<b>Example sentence:</b> $$\"Clustering\\:is\\:nice\"$$<br/>\n",
    "<b>Without params:</b> $$[(\"Clustering\", \"is\", \"nice\")]$$\n",
    "<b>With padding:</b> $$[(None,\\:None,\\:\"Clustering\"), (None,\\:\"Clustering\", \"is\"), ... , (\"is\", \"nice\",\\:None), (\"nice\",\\:None,\\:None)]$$\n",
    "<br/>\n",
    "--> This allows to determine the frequency of words at the beginning of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:00<00:00, 2435.17it/s]\n"
     ]
    }
   ],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for sent in tqdm(sents):\n",
    "    words = word_tokenize(sent)\n",
    "    words = [w.lower() for w in words if re.match(\"[a-z]+\", w.lower()) is not None]\n",
    "    tgs = trigrams(words, pad_left=True, pad_right=True)\n",
    "    for w1, w2, w3 in tgs:\n",
    "        model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Amount of sentences starting with \"The\"\n",
    "print(model[None, None][\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the conditional Probabilities\n",
    "For each stored trigram the probability $P(w3|w1, w2)$ is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2631/2631 [00:00<00:00, 275763.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for w1_w2 in tqdm(model):\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14685314685314685\n"
     ]
    }
   ],
   "source": [
    "# Probability of a sentence starting with \"the\"\n",
    "print(model[(None, None)][\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new sentences\n",
    "Using a random number to ensure that not only the words with highest probability gets assigned as next word, because this will result in almost identical sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of text=3.5140553526798285e-77\n",
      "it is exploratory it does not make any distinction between dependent and independent variables\n",
      "\n",
      "\n",
      "Probability of text=2.8367088304084833e-123\n",
      "unlike lda cluster analysis are hierarchical methods agglomerative or divisive partitioning methods and methods for classifying objects\n",
      "\n",
      "\n",
      "Probability of text=2.310199468872137e-53\n",
      "you can specify initial cluster centers iteratively or classifying objects\n",
      "\n",
      "\n",
      "Probability of text=4.733217903156709e-119\n",
      "these clusters are defined through an analysis of the data objects patterns entities instances observances units into a number of different algorithms and methods for grouping objects of similar objects.cluster analysis is a crucial intermediate step needed for further data analysis and serves as a field grew very quickly with the observed data.clustering techniques apply when there is no class to be had from grouping together similar objectsk means clustering we have the specify the number of clusters groups\n",
      "\n",
      "\n",
      "Probability of text=3.2762832330802307e-24\n",
      "regarding to data mining and a common technique for partitioning a data set into groups or clusters such that similar subjects are joined to form our groups of genes that is they are like members of other clusters\n",
      "\n",
      "\n",
      "Probability of text=6.365339013084812e-74\n",
      "a cluster may be hierarchical a rough division of instances into groups at the top level and each cluster is described by its diameter the maximum distance between these two subjects is given bycluster analysis is a discovery tool that reveals associations patterns relationships and structures in data without explaining why they exist.data clustering is the organization of a set of objects called clusters\n",
      "\n",
      "\n",
      "Probability of text=1.2203776462080822e-40\n",
      "in other words documents within a group be similar or related to one another than objects assigned to different clusters are grouped in such a way that when they do not belong to it calling this type of grouping data objects that are farther apart\n",
      "\n",
      "\n",
      "Probability of text=9.02333674620418e-47\n",
      "the algorithms goal is that the genes share a biological function and are dissimilar to objects not belonging to two different clusters are defined through an analysis of genome-wide expression data as the experimental observation that a set of measured variables into a number of distinct populations or sub-populations\n",
      "\n",
      "\n",
      "Probability of text=9.205671740352643e-28\n",
      "for instance in the dataset\n",
      "\n",
      "\n",
      "Probability of text=6.545803388526796e-11\n",
      "in other groups\n",
      "\n",
      "\n",
      "Probability of text=4.2284043532369015e-25\n",
      "the clusters are not alike\n",
      "\n",
      "\n",
      "Probability of text=6.452981422684003e-84\n",
      "it can be appropriately targetted.cluster analysis is the primary goal\n",
      "\n",
      "\n",
      "Probability of text=3.0697622242064213e-120\n",
      "clearly a cluster may be overlapping an instance may fall into several groups\n",
      "\n",
      "\n",
      "Probability of text=7.300168572409722e-56\n",
      "three data clusters are dissimilar.153 when applied to a compound dataset the resulting clusters provide an overview of the sensitivity of different clustering algorithms to the remaining instances\n",
      "\n",
      "\n",
      "Probability of text=5.495946312295962e-104\n",
      "intuitively patterns within a group and minimal otherwise.cluster analysis is to separate the objects into classes of similar kind into respective categories\n",
      "\n",
      "\n",
      "Probability of text=9.249639926313749e-83\n",
      "you can select one of the following definitions of a particular set of objects in the variables studied called the cluster centroid\n",
      "\n",
      "\n",
      "Probability of text=5.593649594320048e-104\n",
      "major types of cluster analysis see gordon analysis or taxonomy analysis\n",
      "\n",
      "\n",
      "Probability of text=1.3517985859743585e-28\n",
      "for instance in the data objects based only on information found in data and describing the relationships inside the data\n",
      "\n",
      "\n",
      "Probability of text=3.439634085131573e-36\n",
      "in clustering it is being applied in variety of specific methods of clustering could be the process of partitioning or grouping a given set of patterns points or objects events people things etc\n",
      "\n",
      "\n",
      "Probability of text=4.207300203484667e-49\n",
      "clustering is an exploratory data mining software from sas institute.clustering can be possible to create clusters that are initially unknownclustering algorithms partition data objects in a cluster are alike and patterns belonging to other groups\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range(20):\n",
    "    text = [None, None]\n",
    "    prob = 1.0\n",
    "    sentence_finished = False\n",
    "\n",
    "    while not sentence_finished:\n",
    "        r = random.random()\n",
    "        # r = random.uniform(0.3, 1)\n",
    "        # print(\"Random: {}\".format(r))\n",
    "        accumulator = .0\n",
    "        # print(\"Possible words: {}\".format(len(model[tuple(text[-2:])].keys())))\n",
    "        for word in model[tuple(text[-2:])].keys():\n",
    "            accumulator += model[tuple(text[-2:])][word]\n",
    "            # print(\"Accumulator: {}\".format(accumulator))\n",
    "            # print(\"=> {}\".format( accumulator >= r))\n",
    "            prob *= model[tuple(text[-2:])][word]  \n",
    "            if accumulator >= r:\n",
    "                text.append(word)\n",
    "                break\n",
    "\n",
    "        if text[-2:] == [None, None]:\n",
    "            sentence_finished = True\n",
    "    if len(text) > 6:\n",
    "        if not os.path.exists(\"data/sentence_generation_outputs\"):\n",
    "            os.mkdir(\"data/sentence_generation_outputs/\")\n",
    "        file = open(\"data/sentence_generation_outputs/sentence_{}.txt\".format(i+1), \"w\")\n",
    "        file.write(' '.join([t for t in text if t]))\n",
    "        \n",
    "    print(\"Probability of text={}\".format(prob))\n",
    "    print(' '.join([t for t in text if t]))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
