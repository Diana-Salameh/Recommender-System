{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction in Google's Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.\n",
    "\n",
    "The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length English text and the output is a 512 dimensional vector. We apply this model to the STS benchmark for semantic similarity, and the results can be seen in the example notebook made available. The universal-sentence-encoder model is trained with a deep averaging network (DAN) encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple Explanation of DAN [PLACEHOLDER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The stupid proxy.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['http_proxy'] = \"http://proxy.mms-dresden.de:8080\"\n",
    "#os.environ['https_proxy'] = \"http://proxy.mms-dresden.de:8080\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model from TF-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "# The path where tf-hub will cache the model (use an absolute path..) \n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = '/tfhub'\n",
    "\n",
    "#TF-hub will store the name as hex\n",
    "hashlib.sha1(model_url.encode(\"utf8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 3min 54s, total: 7min 21s\n",
      "Wall time: 8min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initial download takes a while till the model is downloaded from tf-hub (~1GB)\n",
    "model = hub.Module(model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing different representation for messages\n",
    "1. Universal Sentence Encoder support Words\n",
    "2. Sentences as well\n",
    "3. As longer a paragraph as more diluted is the resulting embedding. Doesn't include the semantic so good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"clustering\"\n",
    "sentence = \"i love clustering!\"\n",
    "paragraph = \"Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\"\n",
    "\n",
    "\n",
    "messages = [word, sentence, paragraph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return result as np.ndarray: \n",
      "[[-0.03222988 -0.0562827  -0.02492116 ... -0.02649049 -0.04364399\n",
      "  -0.07042836]\n",
      " [ 0.01576823 -0.06964915 -0.02094724 ...  0.06391786 -0.0583086\n",
      "  -0.020761  ]\n",
      " [-0.01098906 -0.04785547 -0.00761339 ... -0.06857846 -0.0258504\n",
      "  -0.06867266]]\n",
      "\n",
      " Pretty print: \n",
      "Message: clustering\n",
      "Embedding size: 512\n",
      "Embedding: [-0.03222987800836563, -0.05628269538283348, -0.02492116019129753, ...]\n",
      "\n",
      "Message: i love clustering!\n",
      "Embedding size: 512\n",
      "Embedding: [0.015768229961395264, -0.06964915245771408, -0.02094724401831627, ...]\n",
      "\n",
      "Message: Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\n",
      "Embedding size: 512\n",
      "Embedding: [-0.010989058762788773, -0.047855474054813385, -0.007613392546772957, ...]\n",
      "\n",
      "CPU times: user 23.3 s, sys: 3.91 s, total: 27.2 s\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as session: \n",
    "    # Initializing global variables in the graph \n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    \n",
    "    message_embeddings = session.run(model(messages))\n",
    "    print(\"Return result as np.ndarray: \")\n",
    "    print(message_embeddings)\n",
    "    \n",
    "    print(\"\\n Pretty print: \")\n",
    "    \n",
    "    for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "        print(\"Message: {}\".format(messages[i]))\n",
    "        print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "        message_embedding_snippet = \", \".join((str(x) for x in message_embedding[:3]))\n",
    "        print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around a little bit with similarity (quick & dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_one = \"I like to categorize different machine types\"\n",
    "paragraph_two = \"I like to know the stock price of my shares\"\n",
    "paragraph_three = \"Cats are just the cutest animals ever!\"\n",
    "\n",
    "definition_1 = \"Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\"\n",
    "definition_2 = \"Regression is a data mining technique used to predict a range of numeric values (also called continuous values), given a particular dataset.\"\n",
    "\n",
    "paragraphes = [paragraph_one, paragraph_two, paragraph_three, definition_1, definition_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.5 s, sys: 2.68 s, total: 26.2 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as session: \n",
    "    # Initializing global variables in the graph \n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    \n",
    "    paragraph_embeddings = session.run(model(paragraphes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = paragraph_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = x[0].reshape(1,-1)\n",
    "x_1 = x[1].reshape(1,-1)\n",
    "x_2 = x[2].reshape(1,-1)\n",
    "x_3 = x[3].reshape(1,-1)\n",
    "x_4 = x[4].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Paragrpah\n",
    "Result: the clustering paragraph is more similar to the clustering as to the regression definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similiartiy between paragraph_one and definition_1: [[0.5987135]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similiartiy between paragraph_one and definition_1: {}\".format(cosine_similarity(x_0, x_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similiartiy between paragraph_one and definition_2: [[0.40741783]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similiartiy between paragraph_one and definition_2: {}\".format(cosine_similarity(x_0, x_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Paragraph\n",
    "Result: the regression paragraph is more similar to the regression as to the clustering definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similiartiy between paragraph_two and definition_1: [[0.19165283]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similiartiy between paragraph_two and definition_1: {}\".format(cosine_similarity(x_1, x_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similiartiy between paragraph_two and definition_2: [[0.36063346]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similiartiy between paragraph_two and definition_2: {}\".format(cosine_similarity(x_1, x_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random paragraph\n",
    "Result: In comparsion to the other results the similarity looks quite small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1499501]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(x_2, x_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00603353]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(x_2, x_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
