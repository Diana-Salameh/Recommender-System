{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to ELMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://tfhub.dev/google/elmo/2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "# The path where tf-hub will cache the model (use an absolute path..) \n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = '/tfhub'\n",
    "\n",
    "#TF-hub will store the name as hex\n",
    "hashlib.sha1(model_url.encode(\"utf8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tfhub to cache modules.\n",
      "CPU times: user 712 ms, sys: 32.8 ms, total: 745 ms\n",
      "Wall time: 756 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initial download takes a while till the model is downloaded from tf-hub (~1GB)\n",
    "elmo = hub.Module(model_url, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Signatures\n",
    "\n",
    "The model takes two types of signatures as input: \n",
    "1. _tokens_: Tokenized paragraphs\n",
    "2. _default_: Normal paragraphs (splitted at spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1 = \"I want to categorize my data\"\n",
    "p_2 = \"i love clustering!!\"\n",
    "messages = [p_1, p_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 240 ms, total: 1.37 s\n",
      "Wall time: 975 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.Session() as sess: \n",
    "    sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    returns = elmo(inputs = messages,\n",
    "                  signature = \"default\",\n",
    "                  as_dict=True)\n",
    "    \n",
    "    \n",
    "    # Everything returns a Tensor\n",
    "    word_embeddings = returns[\"word_emb\"] # the character(word)-based embeddings with shape [batch_size, max_length, 512].\n",
    "    embeddings = returns[\"elmo\"] # the weighted sum of the 3 layers, where the weights are trainable [batch_size, max_length, 1024]\n",
    "    lstm_1 = returns[\"lstm_outputs1\"] # the first LSTM hidden state\n",
    "    lstm_2 = returns[\"lstm_outputs2\"] # the second LSTM hidden state with shape\n",
    "    default = returns[\"default\"] #(Seems to be the average of the words..) fixed mean-pooling of all contextualized word representations with shape [batch_size, 1024].\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_one = \"I like to group different machine types\"\n",
    "paragraph_two = \"I like to know the stock price of my shares\"\n",
    "paragraph_three = \"Cats are just the cutest animals ever!\"\n",
    "\n",
    "definition_1 = \"Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).\"\n",
    "definition_2 = \"Regression is a data mining technique used to predict a range of numeric values (also called continuous values), given a particular dataset.\"\n",
    "\n",
    "paragraphes = [paragraph_one, paragraph_two, paragraph_three, definition_1, definition_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session: \n",
    "    # Initializing global variables in the graph \n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    sentence_tensor = elmo(inputs = paragraphes,\n",
    "                  signature = \"default\",\n",
    "                  as_dict=True)[\"default\"]\n",
    "    sentence_embeddings = session.run(sentence_tensor)\n",
    "    #paragraph_embeddings = session.run(elmo(paragraphes)[\"elmo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1024)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings[0].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = [x.reshape(1,-1) for x in sentence_embeddings]\n",
    "x_0 = sentence_embeddings[0]\n",
    "x_1 = sentence_embeddings[1]\n",
    "x_2 = sentence_embeddings[2]\n",
    "x_3 = sentence_embeddings[3]\n",
    "x_4 = sentence_embeddings[4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Paragrpah\n",
    "Result: the clustering paragraph is more similar to the regression as to the clustering definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similiartiy between paragraph_one and definition_1: [[0.4208754]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similiartiy between paragraph_one and definition_1: {}\".format(cosine_similarity(x_0, x_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similiartiy between paragraph_one and definition_2: [[0.4985751]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similiartiy between paragraph_one and definition_2: {}\".format(cosine_similarity(x_0, x_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Paragraph\n",
    "Result: Both distances are really close.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similiartiy between paragraph_two and definition_1: [[0.35134336]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similiartiy between paragraph_two and definition_1: {}\".format(cosine_similarity(x_1, x_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similiartiy between paragraph_two and definition_2: [[0.47441936]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similiartiy between paragraph_two and definition_2: {}\".format(cosine_similarity(x_1, x_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random paragraph\n",
    "Result: Again the similarity measures are nearly equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.342139]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(x_2, x_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.383528]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(x_2, x_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
