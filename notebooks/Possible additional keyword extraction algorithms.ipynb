{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible keyword extraction algorithms\n",
    "\n",
    "__Shown keyword extraction algorithms:__\n",
    "- __Graph based:__\n",
    "    - TopicRank\n",
    "    - PositionRank\n",
    "    - SingleRank\n",
    "- __Statistical:__\n",
    "    - Yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pke  # Package containing several keyword extractors\n",
    "import os \n",
    "import string \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data files\n",
    "def create_data_files(major_dir: str):\n",
    "    all_together = []\n",
    "    for sub_dir in os.listdir(major_dir):\n",
    "        sub_dir_text = \"\"\n",
    "        sub_dir_path = os.path.join(major_dir, sub_dir)\n",
    "        if os.path.isdir(sub_dir_path):\n",
    "            for file in [x for x in os.listdir(sub_dir_path) if x.endswith(\".txt\")]:\n",
    "                sub_dir_text += open(os.path.join(sub_dir_path, file), \"r\").read() + \"\\n\"\n",
    "        all_together.append(sub_dir_text)\n",
    "        out = open(os.path.join(major_dir, sub_dir+\".txt\"), \"w\")\n",
    "        out.write(sub_dir_text)\n",
    "        out.close()\n",
    "    all_out = open(os.path.join(major_dir, \"all.txt\"), \"w\")\n",
    "    all_out.write(\"\\n\".join(all_together))\n",
    "    all_out.close()\n",
    "    \n",
    "# create_data_files(major_dir=\"../data/datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_data = open(\"../data/datasets/clustering.txt\", \"r\").read()\n",
    "prediction_data = open(\"../data/datasets/prediction.txt\", \"r\").read()\n",
    "pattern_data = open(\"../data/datasets/frequent_pattern_mining.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Rank\n",
    "__Keyword Candidates:__ <br/>\n",
    "- Sequences of Nouns and adjectives\n",
    "- Division in topics -> Overlap between candidates are used for topic creation with Hierarchical Agglomerative Clustering\n",
    "\n",
    "__Scoring:__<br/>\n",
    "- TextRank Scoring \n",
    "\n",
    "__Final selection:__\n",
    "- Multiple possibilities [First in Topic, Frequency of candidate, Centroid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('abstract attribute clustering', 0.07264453569892483)\n",
      "('abstract highdimensional data streams', 0.02765963626368808)\n",
      "('approach similar', 0.02128196996686105)\n",
      "('appropriate groups', 0.018928294256216952)\n",
      "('abstract object set', 0.018589782988967022)\n",
      "('abstract cluster analysis', 0.01681287419785202)\n",
      "('abstract privacy preserving data mining', 0.013131806998692127)\n",
      "('different parameter setting', 0.011291084984061575)\n",
      "('account possible differences', 0.011034804679302686)\n",
      "('introduction', 0.009827086386374377)\n",
      "('certain number', 0.00865657843214086)\n",
      "('classical pattern recognition problem', 0.007278997676732894)\n",
      "('abstract unsupervised learning', 0.007163383361746941)\n",
      "('arbitrary process', 0.007151409611048128)\n",
      "('analysis data clustering', 0.0071386361384713545)\n",
      "('betweengroup dissimilarity', 0.006991440551768367)\n",
      "('abstract hierarchical clustering', 0.006574590709327781)\n",
      "('fundamental machine learning', 0.006441595077420247)\n",
      "('algorithm', 0.006397327735959678)\n",
      "('data noise', 0.006325747430377434)\n"
     ]
    }
   ],
   "source": [
    "topic_rank = pke.unsupervised.TopicRank()\n",
    "topic_rank.load_document(input='../data/datasets/merged_files/clustering.txt', language=\"en\")\n",
    "pos = {'NOUN', 'PROPN', 'ADJ'}\n",
    "stoplist = list(string.punctuation)\n",
    "stoplist += stopwords.words('english')\n",
    "\n",
    "topic_rank.candidate_selection(pos=pos, stoplist=stoplist)\n",
    "topic_rank.candidate_weighting(threshold=0.74, method='average', heuristic=\"frequent\")\n",
    "\n",
    "topic_rank_keyphrases = topic_rank.get_n_best(n=20)\n",
    "for k in topic_rank_keyphrases:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PositionRank\n",
    "__Scoring:__<br/>\n",
    "Uses PageRank system, while including the positioning of the keyword in the sentence in the weightening schema.<br/>\n",
    "The earlier the term is occurring, the more relevant it seems to be. <br/><br/>\n",
    "This will be averaged over all occurrences of the keyword with: <br/><br/>\n",
    "For a word occurring on the $ 2^{nd},\\:5^{th} $ and $ 10^{th} $ position in the text: <br/>\n",
    "$$ W_{Position} = \\frac{1}{2}+\\frac{1}{5}+\\frac{1}{10} = 0.8 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('clustering', 0.05415698811242924)\n",
      "('data', 0.04531772410423927)\n",
      "('cluster', 0.025506177473485103)\n",
      "('analysis', 0.02208116875796451)\n",
      "('clusters', 0.01720518069564107)\n",
      "('similarity', 0.012921219980310828)\n",
      "('study', 0.012123983623622986)\n",
      "('objects', 0.009875554685460523)\n",
      "('hierarchical', 0.008468824608984734)\n",
      "('groups', 0.008409468248675127)\n",
      "('measure', 0.007498115027469089)\n",
      "('introduction', 0.00731539003028165)\n",
      "('learning', 0.0072341393293188895)\n",
      "('method', 0.006577973529407398)\n",
      "('technique', 0.0062962157904784015)\n",
      "('number', 0.005802020729141968)\n",
      "('pattern', 0.005786295272576257)\n",
      "('distance', 0.005358456819104482)\n",
      "('process', 0.005299947407788508)\n",
      "('image', 0.004856405066303605)\n"
     ]
    }
   ],
   "source": [
    "position_rank = pke.unsupervised.PositionRank()\n",
    "position_rank.load_document(input='../data/datasets/merged_files/clustering.txt', language=\"en\", normalization=None)\n",
    "position_rank.candidate_selection(grammar=None, maximum_word_number=1)\n",
    "position_rank.candidate_weighting(window=5, pos=pos, normalized=True)\n",
    "position_rank_keyphrases = position_rank.get_n_best(n=20)\n",
    "for k in position_rank_keyphrases: \n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAKE\n",
    "__Scoring:__<br/>\n",
    "Five different measures used for term weightening (The smaller the overall score the more relevant the keyword):<br/>\n",
    "<ol>\n",
    "    <li><b>Casing:</b><br/>...Weights words with only upper case letters or starting with upper case letters more</li>\n",
    "    <li><b>Word position:</b><br/>...Words occurring in the first words of a document/sentence are assumed to be more relevant</li>\n",
    "    <li><b>Word frequency:</b><br/>...Higher frequent words, higher than the mean frequency, incl. standard deviation, are considered more relevant</li>\n",
    "    <li><b>Word relatedness to context:</b><br/>...Evaluates how strong the term can be seen as a stopword</li>\n",
    "    <li><b>Word DifSentence:</b><br/>...Measures the relative sentence occurrence of terms</li>\n",
    "</ol>\n",
    "Used formulars:\n",
    "<ol>\n",
    "    <li>$ W_{Case} = \\frac{max(TF(U(w)), TF(A(w)))}{log_2(TF(w))} $</li>\n",
    "    <li>$ W_{Position} = log_2(log_2(2+Median(Sen_w))) $</li>\n",
    "    <li>$ W_{Freq} = \\frac{TF(w)}{MeanTF+1*\\sigma} $</li>\n",
    "    <li>$ W_{Rel} = \\Big(0.5+\\Big(\\Big(WL*\\frac{TF(w)}{MaxTf}\\Big)+PL\\Big)\\Big)+                 \\Big(0.5+\\Big(\\Big(WR*\\frac{TF(w)}{MaxTf}\\Big)+PR\\Big)\\Big) $</li>\n",
    "    <li>$ W_{DifSentence} = \\frac{SF(w)}{\\#_{Sentences}} $</li>\n",
    "</ol>\n",
    "\n",
    "__Resulting final keyword score:__ <br/>\n",
    "\n",
    "$$ S(kw) = \\frac{\\prod_{w\\:\\in\\:kw}S(w)}{TF(kw)*(1+\\sum_{w\\:\\in\\:kw}S(w))}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('clustering', 5.2339059914055286e-05)\n",
      "('data', 8.551312067507064e-05)\n",
      "('cluster', 0.0002047752055714894)\n",
      "('analysis', 0.0002816288755117967)\n",
      "('objects', 0.0005342390488141243)\n",
      "('set', 0.0007304004780160237)\n",
      "('groups', 0.0008261452005597773)\n",
      "('different', 0.0008509194617797423)\n",
      "('similar', 0.0009085692575871795)\n",
      "('introduction', 0.0009514261873288945)\n",
      "('unsupervised', 0.0009619977156120488)\n",
      "('one', 0.0009743913004332281)\n",
      "('learning', 0.0010554209851798351)\n",
      "('mining', 0.0010890941142609669)\n",
      "('used', 0.0011428508306604828)\n",
      "('technique', 0.0012973797216807483)\n",
      "('important', 0.0013195233469502265)\n",
      "('similarity', 0.0013518593699869592)\n",
      "('method', 0.0015462505076103267)\n",
      "('number', 0.0018750698777329211)\n"
     ]
    }
   ],
   "source": [
    "yake = pke.unsupervised.YAKE()\n",
    "\n",
    "yake.load_document(input='../data/datasets/clustering.txt', language=\"en\", normalization=None)\n",
    "\n",
    "stoplist = stopwords.words('english')\n",
    "yake.candidate_selection(n=1, stoplist=stoplist)\n",
    "\n",
    "yake.candidate_weighting(window=5, stoplist=stoplist, use_stems=False)\n",
    "\n",
    "threshold = 0.8\n",
    "yake_keyphrases = yake.get_n_best(n=20, threshold=threshold)\n",
    "\n",
    "for k in yake_keyphrases: \n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SingleRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('clustering clustering', 0.0417691440080825)\n",
      "('clustering', 0.041542364008082505)\n",
      "('data clustering', 0.03848422204952038)\n",
      "('data', 0.03541291009095827)\n",
      "('analysis data clustering', 0.03187077387674159)\n",
      "('clustering technique clustering', 0.029634409758496426)\n",
      "('clustering algorithm clustering', 0.02957903880865547)\n",
      "('cluster analysis data clustering', 0.02894413973752938)\n",
      "('statistical clustering clustering', 0.02871830232981528)\n",
      "('soft clustering clustering', 0.028481260829131248)\n",
      "('clustering overview clustering', 0.02826530338314274)\n",
      "('unsupervised data clustering', 0.028171486610169192)\n",
      "('method data clustering', 0.027908073749125382)\n",
      "('clustering paradigm clustering', 0.0278543916333915)\n",
      "('introduction data clustering', 0.02742781223923391)\n",
      "('abstract data clustering', 0.027181573275699374)\n",
      "('algorithm data clustering', 0.027147170836280723)\n",
      "('multidimensional data clustering', 0.02661355081439924)\n",
      "('background data clustering', 0.026436633738617234)\n",
      "('outlier data clustering', 0.02619973489196082)\n"
     ]
    }
   ],
   "source": [
    "single_rank = pke.unsupervised.SingleRank()\n",
    "single_rank.load_document(input='../data/datasets/clustering.txt', language=\"en\", normalization=None)\n",
    "\n",
    "single_rank.candidate_selection(pos=pos)\n",
    "\n",
    "single_rank.candidate_weighting(window=4, pos=pos, normalized=True)\n",
    "\n",
    "single_rank_keyphrases = single_rank.get_n_best(n=20)\n",
    "for k in single_rank_keyphrases:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopicalPageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LatentDirichletAllocation' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5c8602df5954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../data/datasets/all.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_weighting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model_trainings/LDA/LDA_for_key_extr.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtpr_keyphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rs/lib/python3.6/site-packages/pke/unsupervised/graph_based/single_tpr.py\u001b[0m in \u001b[0;36mcandidate_weighting\u001b[0;34m(self, window, pos, lda_model, stoplist, normalized)\u001b[0m\n\u001b[1;32m    154\u001b[0m              \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m              \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_dirichlet_component_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m              model.doc_topic_prior_) = pickle.load(f)\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# build the document representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'LatentDirichletAllocation' object is not iterable"
     ]
    }
   ],
   "source": [
    "tpr = pke.unsupervised.TopicalPageRank()\n",
    "\n",
    "tpr.load_document(input='../data/datasets/all.txt', language='en')\n",
    "tpr.candidate_selection(grammar=None)\n",
    "tpr.candidate_weighting(window=4, pos=pos, lda_model='model_trainings/LDA/LDA_for_key_extr.gz')\n",
    "\n",
    "tpr_keyphrases = tpr.get_n_best(n=20)\n",
    "for k in tpr_keyphrases:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
