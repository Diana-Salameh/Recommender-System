{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Data Set Into Sentences\n",
    "The idea is to split each file into it's sentences and to filter them for single keywords, to reduce noise. In addition, a context window can be specified, which keeps the sentences arround the filtered sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/Users/Daniel/Downloads/final_datasets/full_dataset\"\n",
    "out_dir = \"daniel_181218_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_lst = [\"clustering is\"]\n",
    "pm_lst = [\"pattern mining\", \"sequence mining\", \"association rule\", \"sequential pattern\"]\n",
    "prediction_lst = [\"regression is\", \"classification is\"]\n",
    "#association_lst = [\"association rule mining is\", \"pattern\", \"sequences\", \"mining\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_lst = {\"clustering\": clustering_lst,\n",
    "               \"prediction\": prediction_lst,\n",
    "               \"frequent_pattern_mining\": pm_lst}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_window = 1 # bidirectional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir created\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    print(\"dir created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading, Splitting and Saving Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 5s, sys: 28.7 s, total: 15min 34s\n",
      "Wall time: 16min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for root, dirs, files in os.walk(dir_path):\n",
    "    for _dir in dirs: \n",
    "        for txt_file in [x for x in os.listdir(os.path.join(root, _dir)) if x.endswith((\".txt\", \".TXT\"))]:\n",
    "            # Class name = dir name\n",
    "            class_name = _dir\n",
    "            #Read File\n",
    "            file_name = os.path.join(root, _dir, txt_file)\n",
    "            file = open(file_name, \"r\")\n",
    "            txt = file.read()\n",
    "            file.close()\n",
    "            # Txt to List[Sentences]\n",
    "            sentences = sent_tokenize(txt)\n",
    "            # Abstracts\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                keywords = keyword_lst[class_name]\n",
    "                for keyword in keywords:\n",
    "                    if keyword in sentence:\n",
    "                        text = []\n",
    "                        main_sentence = sentence # the sentence in the middle of the context window\n",
    "                        # getting the context\n",
    "                        if i != 0:\n",
    "                            # check if list is big enough for a bidirectional check\n",
    "                            if (i-context_window) >= 0 and (i+context_window+1) <= len(sentences):\n",
    "                                left_context = i-context_window\n",
    "                                right_context = i+context_window\n",
    "                                text = sentences[left_context:(right_context+1)]\n",
    "                            # Only space left on the left side\n",
    "                            elif (i-context_window) >= 0: \n",
    "                                left_context = i-context_window\n",
    "                                text = sentences[left_context:(i+1)]\n",
    "                            # only space at the right side\n",
    "                            elif len(sentences) <= (i+context_window+1) and i+1 != len(sentences):\n",
    "                                right_context = i+context_window\n",
    "                                text = sentences[i: (right_context+1)]\n",
    "                        else:\n",
    "                            text.append(main_sentence)\n",
    "                        \n",
    "                        # create dirs\n",
    "                        if not os.path.isdir(os.path.join(out_dir, _dir)):\n",
    "                            os.mkdir(os.path.join(out_dir, _dir))\n",
    "                            #print(\"dir created\")\n",
    "                        \n",
    "                        # write file\n",
    "                        file_name_out = os.path.join(out_dir, _dir, txt_file)\n",
    "                        file_out = open(file_name_out, \"w+\")\n",
    "                        for i, txt in enumerate(text):\n",
    "                            txt = re.sub(' +',' ',txt).lower().lstrip(\" \").lstrip(\"\\n\")\n",
    "                            txt_split = txt.split(\" \", 1)\n",
    "                            if txt_split[0] == \"abstract\":\n",
    "                                txt = txt_split[1]\n",
    "                            if txt_split[0].isalpha():\n",
    "                                if i > 0:\n",
    "                                    file_out.write(\" \"+txt.lower())\n",
    "                                else:\n",
    "                                    file_out.write(txt.lower())\n",
    "                        file_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
